
from Jade require "crypto_verify/16/amd64/common/crypto_verify_16.jinc"

// little endian for loads and stores
inline fn __load2(reg u64 p) -> reg u64[2]
{
  reg u64[2] x;

  x[0] = [p + 0];
  x[1] = [p + 8];

  return x;
}


inline fn __load_add(reg u64[3] h, reg u64 in) -> reg u64[3]
{
  reg bool cf;

  cf, h[0] += [in + 0];
  cf, h[1] += [in + 8] + cf;
   _, h[2] +=        1 + cf;

  return h;
}


inline fn __load_last_add_mask(reg u64 len) -> reg u64[2], reg u64[2]
{
  reg bool cf;
  reg u64 s0 s1 s2 nb b m;
  reg u64[2] m1 m2;

  ?{}, s0 = #set0();
  s1  = len;
  s1 &= 7;
  s1 <<= 3; // [0,8,...,56]

  // if 4th bit is set (>=8) then m = 0 else m = 0xffff..
  b   = len;
  b >>= 3;
  nb  = b;
  nb ^= 1;
  m   = b;
  m  -= 1;

  // swap if < 8
  s2  = s1;
  s2 &= m;
  s0 ^= s2;
  s1 ^= s2;

  m1[0] = nb;
  m1[1] =  b;
  m1[0] <<= s0;
  s0 = s1; //rcx
  m1[1] <<= s0;

  m2 = #copy(m1);

  cf, m2[0] -= 1;
   _, m2[1] -= 0 - cf;

  return m2, m1;
}


inline fn __load_last_add(reg u64[3] h, reg u64 in len) -> reg u64[3]
{
  inline int i;
  reg bool cf;
  reg u64[2] v m1 m2;

  m1, m2 = __load_last_add_mask(len);

  for i=0 to 2
  { v[i] = [in + 8*i];
    v[i] &= m1[i];
    v[i] |= m2[i];
  }

  cf, h[0] += v[0];
  cf, h[1] += v[1] + cf;
   _, h[2] +=    0 + cf;

  return h;
}


inline fn __store2(reg u64 p, reg u64[2] x)
{
  [p + 0] = x[0];
  [p + 8] = x[1];
}


inline fn __clamp(reg u64 k) -> reg u64[3]
{
  reg u64[3] r;

  r[0] = [k + 0];
  r[1] = [k + 8];
  r[0] &= 0x0ffffffc0fffffff;
  r[1] &= 0x0ffffffc0ffffffc;
  r[2] = r[1];
  r[2] >>= 2;
  r[2] += r[1];

  return r;
}


// h += s
inline fn __add2(reg u64[2] h s) -> reg u64[2]
{
  reg bool cf;

  cf, h[0] += s[0];
   _, h[1] += s[1] + cf;

  return h;
}


// r[2] = r[1] / 4 * 5
inline fn __mulmod(reg u64[3] h r) -> reg u64[3]
{
  reg bool cf;
  reg u64[3] t;
  reg u64 h0 h1 l0 l1 rdx;

  // ////////////////////////
                                              rdx = h[0];
                                              h0  = h[2];     // < 7
        h0         *= r[2];                                   // < 2**63   // 0x77ffffe277ffffe2
        h1,   t[0]  = #MULX ( rdx, r[0] );                    // < 2**124  // 0x0ffffffc_0ffffffe, 2**64-1
  t[2], t[1]        = #MULX ( rdx, r[1] );                    // < 2**124  // 0x0ffffffc_0ffffffb, 2**64-1
  h[2]             *= r[0];                                   // < 2**63   // 0x5fffffe85ffffffa
                                              h[2] += t[2];   // < 2**63   // 0x6fffffe46ffffff5
                                              h0   += h1;     // < 2**64   // 0x87ffffde87ffffe0
                                              rdx   = h[1];
        h[1], l0    = #MULX ( rdx, r[2] );                    // < 2**125  // 0x13fffffb_13fffffa, 2**64-1
  t[2], l1          = #MULX ( rdx, r[0] );                    // < 2**124  // 0x0ffffffc_0ffffffe, 2**64-1

  // ////////////////////////
  // h[2]  h[1]
  //       h0
  // t[2]  t[1]  t[0]
  //       l1    l0

  _ , h[1] += h0;                                              // < 2**64   // 0x8bffffdd8bffffdc
  cf, t[0] += l0;
  cf, h[1] += t[1] + cf;
  cf, h[2] += t[2] + cf;

  h[0] = 0xfffffffffffffffc;
  t[2] = h[2];
  h[0] &= h[2];
  t[2] >>= 2;
  h[2] &= 0x3;

  _ , h[0] += t[2];
  cf, h[0] += t[0];
  cf, h[1] += l1 + cf;
  _ , h[2] +=  0 + cf;

  return h;
}


inline fn __freeze(reg u64[3] h) -> reg u64[2]
{
  reg bool cf;
  reg u64[2] g;
  reg u64 g2 mask;

  g[0] = h[0];
  g[1] = h[1];
  g2 = h[2];

  // 1.
  //         <= 6 then g[2] <= 7 (111b)
  // if h[2] <= 4 then g[2] <= 5 (101b)
  cf, g[0] += 5;
  cf, g[1] += 0 + cf;
   _, g2 += 0 + cf;

  // 2. by 1. 1 bit set at most
  g2 >>= 2;

  // g2 == 1 => mask = 0xff..ff
  mask = -g2;

  g[0] ^= h[0];
  g[1] ^= h[1];

  g[0] &= mask;
  g[1] &= mask;

  // if mask then h[0..1] ^= (g[0..1] ^ h[0..1])
  // else         h[0..1] ^= 0
  g[0] ^= h[0];
  g[1] ^= h[1];

  return g;
}


inline fn __poly1305_setup_ref(reg u64 k) -> reg u64[3], reg u64[3], reg u64
{
  inline int i;
  reg u64[3] h r;

  for i=0 to 3 { h[i] = 0; }
  r = __clamp(k);
  k += 16;

  return h, r, k;
}


inline fn __poly1305_update_ref(reg u64 in inlen, reg u64[3] h r) -> reg u64, reg u64, reg u64[3]
{
  while(inlen >= 16)
  {
    h = __load_add(h, in);
    h = __mulmod(h, r);
    in += 16;
    inlen -= 16;
  }

  return in, inlen, h;
}


inline fn __poly1305_last_ref(reg u64 in inlen k, reg u64[3] h r) -> reg u64[2]
{
  reg u64[2] m s h2;

  if(inlen > 0)
  { h = __load_last_add(h, in, inlen);
    h = __mulmod(h, r);
  }

  h2 = __freeze(h);
  s = __load2(k);
  h2 = __add2(h2, s);

  return h2;
}


inline fn __poly1305_r_ref(reg u64 in inlen k) -> reg u64[2]
{
  reg u64[3] h r;
  reg u64[2] h2;

  h, r, k = __poly1305_setup_ref(k);
  in, inlen, h = __poly1305_update_ref(in, inlen, h, r);
  h2 = __poly1305_last_ref(in, inlen, k, h, r);

  return h2;
}


inline fn __poly1305_ref(reg u64 out in inlen k)
{
  reg u64[2] h2;
  h2 = __poly1305_r_ref(in, inlen, k);
  __store2(out, h2);
}


inline fn __poly1305_verify_ref(reg u64 h in inlen k) -> reg u64
{
  reg u64[2] hc;
  reg u64 r;

  hc = __poly1305_r_ref(in, inlen, k);
  r = __crypto_verify_p_u8x16_r_u64x2(h, hc);
  return r;
}

